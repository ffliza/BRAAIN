
<p align="center">
  <img src="img/block_logo.png" alt="Project Logo" width="300"> </p>
  
  
<!--  *A research project funded by [EPSRC](https://epsrc.ukri.org/) and [AISI](https://www.aisi.gov.uk/)*  

  ![GitHub last commit](https://img.shields.io/github/last-commit/your-repo/your-project?color=5bc0be)
  ![License](https://img.shields.io/badge/license-MIT-blue) -->


## Project Details

**Title:** BRA(AI)N - Building Resilience and Accountability in Artificial Intelligence Navigation

**Funder(s):** UKRI EPSRC and AI Security Institute (AISI)

**Start Date:** February 2025

**End Date:** February 2026

**Status:** Current




## Overview
<!-- **Investigating trustworthy AI systems for education** through resilience enhancement against adversarial attacks, biases, and environmental uncertainties while ensuring transparent decision-making. -->


This research project seeks to advance understanding of artificial intelligence (AI) and inform educational policy by examining the role of Generative Artificial Intelligence (GenAI) in UK Higher Education (HE). With a focus on technologies such as ChatGPT and DeekSeek, the project explores how these tools are being embedded into academic practice. It considers not only their potential advantages and risks but also the preparedness and resilience of users navigating this evolving digital landscape.
At its core, the project is committed to producing robust, evidence-based insights that support the ethical, effective and responsible integration of AI across the HE sector. The findings will be presented in a detailed report and shared with key stakeholders, including universities and relevant government departments. To extend its reach and impact, the study will also generate peer-reviewed academic publications, contributing to ongoing scholarly discussions and future policy development.

## Purpose and Research Focus
This project welcomes the participation of a wide range of individuals‚Äîuniversity students, academic staff, administrators, policymakers, regulators and AI industry experts‚Äîto explore the use and implications of GenAI in HE. It seeks to understand the motivations behind the adoption of these tools and to examine the impact when such technologies become unreliable or inaccessible.
By drawing on participants‚Äô real-world experiences with GenAI in teaching, learning and assessment, the study aims to uncover practical insights into their value, limitations and ethical implications. These perspectives are essential to shaping responsible and evidence-informed policies for the integration of GenAI technologies in the HE landscape.

## Get Involved
Ethically approved by the University of East Anglia (Ref: ETH2425-1497), this interdisciplinary research will adopt a mixed-methods approach, conducted in two distinct phases:

#### Phase One: Take-Home Assessment and Evaluation
Undergraduate and postgraduate students from a range of academic backgrounds will be invited to complete take-home assessments. Participant recruitment will follow Equality, Diversity and Inclusion (EDI) principles to ensure a fair and representative sample. Participation is entirely voluntary, with the freedom to withdraw at any time without the need to provide a reason.

#### Phase Two: In-Depth Interviews and Focus Groups
This phase will involve individual interviews and focus group discussions with students and educators from Phase One, as well as policymakers, regulators and industry experts. These sessions aim to provide deeper insight into participants‚Äô perspectives, behaviours and decision-making processes related to GenAI use in academic and professional environments.

To acknowledge participants‚Äô time, insight and expertise, appropriate financial incentives and other forms of compensation will be provided. These will be administered in line with ethical research practices and financial compliance requirements, ensuring transparency, fairness and respect for all contributors.

üîπ Project Information [click to download](docs/Participant Information Sheet Simplified.pdf)

üîπ Concent Form [click to download](docs/PARTICIPANT CONSENT FORM.pdf)


<!-- 
### Key Objectives
‚úî **Robustness**: Improve artificial intelligence reliability in dynamic educational environments  
‚úî **Accountability**: Develop transparent decision support frameworks  
‚úî **Impact**: Test systems in real-world skill development scenarios  
-->

**Focus Areas**:  
üîπ Artificial Intelligence Safety & Security
üîπ Ethical Compliance and Accountability
üîπ Accessibility in EdTech
üîπ Policy Development

<!--
## Get Involved
We welcome collaborations from researchers and educators!

üìß Contact: f.liza@uea.ac.uk
üì¢ Follow: @ProjectTwitterHandle

Would you be interested in contributing? Reach out via email!
-->

<!--
## üõ† Methodology  
### **Technical Approach**  
- **Adversarial Training**: Stress-testing AI models against perturbations.  
- **Explainability Tools**: SHAP, LIME, or custom interpretability modules.  
- **Evaluation** Controlled educational experiments.
-->


## Research Team
<!-- **Co-Lead Investigator**:  -->

- [Dr Farhana Ferdousi Liza](https://research-portal.uea.ac.uk/en/persons/farhana-ferdousi-liza-fhea), *University of East Anglia, UK.* 
- [Dr Katherine Deane](https://research-portal.uea.ac.uk/en/persons/katherine-deane), *University of East Anglia, UK.*
- [Dr Shoaib Ahmed](https://profiles.sussex.ac.uk/p590456-shoaib-ahmed/professional), *University of Sussex, UK.*




<!--
## Partners
<p align="center"> <a href="https://epsrc.ukri.org/"> <img src="img/UKRI.png" alt="UKRI EPSRC" height="50"> </a> &nbsp;&nbsp;&nbsp; <a href="https://www.aisi.gov.uk/"> <img src="img/AISI.svg" alt="AISI" height="50"> </a> &nbsp;&nbsp;&nbsp; <a href="https://www.microsoft.com/en-us/research/"> <img src="img/MS.png" alt="Microsoft" height="70"> </a> &nbsp;&nbsp;&nbsp; </p>

Grant Support: EPSRC/AISI Grant #YYYYY
-->

### License

This project is licensed under the MIT License - see the LICENSE file for details.

<p align="center"> <sub>Built with ‚ù§Ô∏è by the Responsible AI Education Team</sub> </p> 



